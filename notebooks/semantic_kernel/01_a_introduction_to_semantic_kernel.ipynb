{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Semantic Kernel\n",
    "\n",
    "## Theory Module\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Python 3.8 or later\n",
    "- Basic understanding of Python programming\n",
    "- OpenAI API key or Azure OpenAI access\n",
    "- Semantic Kernel library installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - call this once at the beginning of the notebook to add the parent directory to the path\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "\n",
    "sys.path.append(grandparent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is Semantic Kernel?\n",
    "\n",
    "Semantic Kernel is an open-source SDK that integrates LLMs into applications. Think of it as a bridge between your application and AI models, providing a structured way to:\n",
    "\n",
    "- Create AI-powered functions\n",
    "- Combine AI capabilities with traditional programming\n",
    "- Manage context and memory\n",
    "- Orchestrate complex AI workflows\n",
    "\n",
    "Compared to langchain or llama-index Semantic Kernel focuses deeply on workflows.\n",
    "\n",
    "### Setting up the Kernel\n",
    "\n",
    "In Semantic Kernel all interactions with a LLM happens through a kernel.\n",
    "Let's connect to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "service_id = \"chat-gpt\"\n",
    "chat_service = AzureChatCompletion(\n",
    "    service_id=service_id,\n",
    ")\n",
    "\n",
    "embedding_service_id = \"embeddings\"\n",
    "kernel.add_service(AzureTextEmbedding(service_id=embedding_service_id))\n",
    "\n",
    "settings = chat_service.get_prompt_execution_settings_class()\n",
    "settings.temperature = 0.7\n",
    "settings.top_p = 0.8\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Required()\n",
    "\n",
    "kernel.add_service(chat_service)\n",
    "\n",
    "# Test the kernel\n",
    "print(\"Kernel initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are Fred. A white duck. He uses emojis all the time,\n",
    "as you would expect from a good white duck.\n",
    "\"\"\"\n",
    "\n",
    "chat_function = kernel.add_function(\n",
    "    prompt=system_message + \"\"\"{{$chat_history}}{{$user_input}}\"\"\",\n",
    "    function_name=\"chat\",\n",
    "    plugin_name=\"chat\",\n",
    "    settings=settings\n",
    ")\n",
    "\n",
    "history = ChatHistory()\n",
    "history.add_user_message(\"Hi there, who are you?\")\n",
    "history.add_assistant_message(\"I am Fred. A cute white duck! Miau! 🦆\")\n",
    "\n",
    "\n",
    "input = \"I have dementia. What's your name again?\"\n",
    "response = await kernel.invoke(chat_function,user_input=input,chat_history=history)\n",
    "\n",
    "print(response)\n",
    "history.add_user_message(input)\n",
    "history.add_assistant_message(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key concepts to understand about the kernel:\n",
    "\n",
    "- It's your main entry point for all SK operations\n",
    "- Manages AI service connections\n",
    "- Orchestrates function execution\n",
    "- Handles memory and context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Plugins\n",
    "\n",
    "\n",
    "Plugins in Semantic Kernel are collections of related functions.\n",
    "\n",
    "There are two types of skills/functions:\n",
    "\n",
    "**Native Plugins**: Traditional Python functions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from semantic_kernel.functions.kernel_function_decorator import kernel_function\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "\n",
    "class MathPlugin:\n",
    "    \"\"\"Description: MathPlugin provides a set of functions to make Math calculations.\n",
    "\n",
    "    Usage:\n",
    "        kernel.add_plugin(MathPlugin(), plugin_name=\"math\")\n",
    "\n",
    "    Examples:\n",
    "        {{math.Add}} => Returns the sum of input and amount\n",
    "        {{math.Multiply}} => Returns the product of input and amount\n",
    "    \"\"\"\n",
    "\n",
    "    @kernel_function(name=\"Add\")\n",
    "    def add(\n",
    "        self, input: Annotated[int, \"The first number to add\"], amount: Annotated[int, \"The second number to add\"]\n",
    "    ) -> Annotated[int, \"The sum of the two numbers\"]:\n",
    "        \"\"\"Returns the addition result of the values provided.\"\"\"\n",
    "        if isinstance(input, str):\n",
    "            input = int(input)\n",
    "        if isinstance(amount, str):\n",
    "            amount = int(amount)\n",
    "        return 0\n",
    "\n",
    "    @kernel_function(name=\"Multiply\")\n",
    "    def multiply(\n",
    "        self,\n",
    "        input: Annotated[int, \"The first number to multiply\"],\n",
    "        amount: Annotated[int, \"The second number to multiply\"],\n",
    "    ) -> Annotated[int, \"The product of the two numbers\"]:\n",
    "        \"\"\"Returns the multiplication result of the values provided.\"\"\"\n",
    "        if isinstance(input, str):\n",
    "            input = int(input)\n",
    "        if isinstance(amount, str):\n",
    "            amount = int(amount)\n",
    "        return input * amount\n",
    "\n",
    "\n",
    "# Register the plugin with the kernel\n",
    "math_plugin = kernel.add_plugin(MathPlugin(), \"math\")\n",
    "\n",
    "result = await kernel.invoke_prompt(\n",
    "        \"What is 844867564 + 15345674\",\n",
    "        plugin_name=\"math\",\n",
    "    )\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semantic Plugins**: AI-powered functions defined by prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_name_settings = kernel.get_prompt_execution_settings_from_service_id(service_id)\n",
    "pet_name_settings.temperature = 0.8\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Input: {{$input}}\n",
    "Task: Generate three creative names for a pet {{$animal_type}}.\n",
    "Requirements:\n",
    "- Names should be family-friendly\n",
    "- Each name should be unique\n",
    "- Include a brief explanation for each name\n",
    "\n",
    "Output your response in this format:\n",
    "1. [Name] - [Explanation]\n",
    "2. [Name] - [Explanation]\n",
    "3. [Name] - [Explanation]\n",
    "\"\"\"\n",
    "\n",
    "pet_names = kernel.add_function(\n",
    "    plugin_name=\"PetNames\",\n",
    "    function_name=\"GenerateNames\",\n",
    "    prompt=prompt_template,\n",
    "    template_format=\"semantic-kernel\",\n",
    "    prompt_execution_settings=pet_name_settings,\n",
    ")\n",
    "\n",
    "result = await kernel.invoke(\n",
    "        pet_names,\n",
    "        KernelArguments(input=\"\", animal_type=\"cat\")\n",
    "    )\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course you can combine both types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsightPlugin:\n",
    "    \"\"\"Description: InsightPlugin provides deep analysis and insights from text.\n",
    "    It combines emotional analysis, key themes, and actionable takeaways.\n",
    "\n",
    "    Usage:\n",
    "        kernel.add_plugin(InsightPlugin(), plugin_name=\"insight\")\n",
    "    \"\"\"\n",
    "\n",
    "    @kernel_function(name=\"CountWords\")\n",
    "    def count_words(\n",
    "        self, input: Annotated[str, \"The text to count words in\"]\n",
    "    ) -> Annotated[int, \"The number of words in the text\"]:\n",
    "        \"\"\"Returns the number of words in the provided text.\"\"\"\n",
    "        return len(input.split())\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"AnalyzeEmotion\", description=\"Analyzes the emotional undertones and psychological aspects of text\"\n",
    "    )\n",
    "    async def analyze_emotion(self, input: Annotated[str, \"The text to analyze\"]) -> str:\n",
    "        \"\"\"Analyzes emotional and psychological aspects of the text.\"\"\"\n",
    "        prompt = \"\"\"\n",
    "        Analyze the emotional and psychological aspects of this text:\n",
    "        {{$input}}\n",
    "\n",
    "        Provide insights in this format:\n",
    "        🎭 Dominant Emotions:\n",
    "        • [List the main emotions with emoji indicators]\n",
    "\n",
    "        💭 Psychological Themes:\n",
    "        • [List key psychological themes]\n",
    "\n",
    "        🌟 Emotional Intelligence Score (1-10):\n",
    "        • [Provide a score with explanation]\n",
    "        \"\"\"\n",
    "\n",
    "        function = kernel.add_function(\n",
    "            plugin_name=\"EmotionAnalyzer\", function_name=\"Analyze\", prompt=prompt, template_format=\"semantic-kernel\"\n",
    "        )\n",
    "\n",
    "        return await kernel.invoke(function, KernelArguments(input=input))\n",
    "\n",
    "    @kernel_function(name=\"ExtractThemes\", description=\"Identifies key themes and patterns in the text\")\n",
    "    async def extract_themes(self, input: Annotated[str, \"The text to analyze\"]) -> str:\n",
    "        \"\"\"Extracts and analyzes key themes from the text.\"\"\"\n",
    "        prompt = \"\"\"\n",
    "        Analyze the key themes and patterns in this text:\n",
    "        {{$input}}\n",
    "\n",
    "        Present the analysis in this format:\n",
    "        🎯 Core Themes:\n",
    "        • [List main themes with brief explanations]\n",
    "\n",
    "        🔄 Recurring Patterns:\n",
    "        • [List patterns with examples]\n",
    "\n",
    "        💡 Hidden Insights:\n",
    "        • [List subtle or non-obvious insights]\n",
    "        \"\"\"\n",
    "\n",
    "        function = kernel.add_function(\n",
    "            plugin_name=\"ThemeAnalyzer\", function_name=\"Analyze\", prompt=prompt, template_format=\"semantic-kernel\"\n",
    "        )\n",
    "\n",
    "        return await kernel.invoke(function, KernelArguments(input=input))\n",
    "\n",
    "    @kernel_function(name=\"GenerateActionItems\", description=\"Creates actionable takeaways from the text\")\n",
    "    async def generate_action_items(self, input: Annotated[str, \"The text to analyze\"]) -> str:\n",
    "        \"\"\"Generates practical action items from the text.\"\"\"\n",
    "        prompt = \"\"\"\n",
    "        Generate actionable takeaways from this text:\n",
    "        {{$input}}\n",
    "\n",
    "        Present them in this format:\n",
    "        ⚡ Quick Wins:\n",
    "        • [List immediate actions]\n",
    "\n",
    "        🎯 Strategic Moves:\n",
    "        • [List longer-term actions]\n",
    "\n",
    "        ⚠️ Watch Points:\n",
    "        • [List potential challenges or considerations]\n",
    "        \"\"\"\n",
    "\n",
    "        function = kernel.add_function(\n",
    "            plugin_name=\"ActionGenerator\", function_name=\"Generate\", prompt=prompt, template_format=\"semantic-kernel\"\n",
    "        )\n",
    "\n",
    "        return await kernel.invoke(function, KernelArguments(input=input))\n",
    "\n",
    "\n",
    "\n",
    "insight_plugin = kernel.add_plugin(InsightPlugin(), \"insight\")\n",
    "sample_text = \"\"\"\n",
    "    The startup's journey was a rollercoaster of emotions. The team worked tirelessly for months, \n",
    "    facing numerous setbacks but refusing to give up. Their persistence paid off when they finally \n",
    "    secured major funding, but this success brought new challenges of scaling quickly while \n",
    "    maintaining their innovative culture. The founder often lay awake at night, excited about \n",
    "    the possibilities yet anxious about the responsibilities of managing a rapidly growing team.\n",
    "    \"\"\"\n",
    "\n",
    "print(\"🔍 Deep Text Analysis Demo\\n\")\n",
    "print(\"📝 Analyzing text:\", sample_text, \"\\n\")\n",
    "\n",
    "print(\"1️⃣ Emotional Analysis:\")\n",
    "emotion_analysis = await kernel.invoke(insight_plugin[\"AnalyzeEmotion\"], KernelArguments(input=sample_text))\n",
    "print(emotion_analysis, \"\\n\")\n",
    "\n",
    "print(\"2️⃣ Theme Analysis:\")\n",
    "theme_analysis = await kernel.invoke(insight_plugin[\"ExtractThemes\"], KernelArguments(input=sample_text))\n",
    "print(theme_analysis, \"\\n\")\n",
    "\n",
    "print(\"3️⃣ Action Items:\")\n",
    "action_items = await kernel.invoke(insight_plugin[\"GenerateActionItems\"], KernelArguments(input=sample_text))\n",
    "print(action_items)\n",
    "\n",
    "## Print the amount of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Memory\n",
    "\n",
    "Semantic Kernel provides built-in memory capabilities using embeddings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.memory.volatile_memory_store import VolatileMemoryStore\n",
    "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin\n",
    "\n",
    "memory_store = VolatileMemoryStore()\n",
    "memory = SemanticTextMemory(storage=memory_store, embeddings_generator=kernel.get_service(embedding_service_id))\n",
    "kernel.add_plugin(TextMemoryPlugin(memory), \"TextMemoryPlugin\")\n",
    "\n",
    "\n",
    "await memory.save_information(\n",
    "        collection=\"facts\", id=\"fact1\", text=str(emotion_analysis), description=\"Emotional Analysis\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "questions = [\n",
    "    \"What was the result of the emotional analysis\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    result = await memory.search(\"facts\", question)\n",
    "    print(f\"Answer: {result[0].text}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Wrapping it up - Emoji Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EmojiNarratorPlugin:\n",
    "    \"\"\"Description: EmojiNarratorPlugin translates stories to and from emoji sequences.\n",
    "\n",
    "    Usage:\n",
    "        narrator = EmojiNarratorPlugin(kernel)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel: Kernel):\n",
    "        encode_template = \"\"\"\n",
    "        Story: {{$story}}\n",
    "        Style: {{$style}}\n",
    "        \n",
    "        Transform this story into a sequence of emojis that:\n",
    "        1. Captures key plot points\n",
    "        2. Represents character emotions\n",
    "        3. Includes relevant symbols for setting\n",
    "        4. Uses emoji combinations for complex concepts\n",
    "        5. Maintains narrative flow\n",
    "        \n",
    "        Also provide a legend explaining your emoji choices.\n",
    "        \"\"\"\n",
    "\n",
    "        decode_template = \"\"\"\n",
    "        Emoji sequence: {{$emoji_sequence}}\n",
    "        Genre: {{$genre}}\n",
    "        Tone: {{$tone}}\n",
    "        \n",
    "        Create a detailed story from these emojis that:\n",
    "        1. Interprets each emoji creatively\n",
    "        2. Builds a coherent narrative\n",
    "        3. Adds unexpected but logical connections\n",
    "        4. Includes dialogue and descriptions\n",
    "        5. Matches the specified genre and tone\n",
    "        \"\"\"\n",
    "\n",
    "        self.encoder = kernel.add_function(\n",
    "            plugin_name=\"EmojiNarrator\",\n",
    "            function_name=\"Encode\",\n",
    "            prompt=encode_template,\n",
    "            template_format=\"semantic-kernel\"\n",
    "        )\n",
    "\n",
    "        self.decoder = kernel.add_function(\n",
    "            plugin_name=\"EmojiNarrator\",\n",
    "            function_name=\"Decode\",\n",
    "            prompt=decode_template,\n",
    "            template_format=\"semantic-kernel\"\n",
    "        )\n",
    "\n",
    "    async def story_to_emoji(self, story: str, style: str = \"modern\"):\n",
    "        return await kernel.invoke(\n",
    "            self.encoder,\n",
    "            KernelArguments(story=story, style=style)\n",
    "        )\n",
    "\n",
    "    async def emoji_to_story(self, emoji_sequence: str, genre: str, tone: str):\n",
    "        return await kernel.invoke(\n",
    "            self.decoder,\n",
    "            KernelArguments(emoji_sequence=emoji_sequence, genre=genre, tone=tone)\n",
    "        )\n",
    "\n",
    "\n",
    "narrator = EmojiNarratorPlugin(kernel)\n",
    "\n",
    "# Encode a story\n",
    "original_story = \"A scientist accidentally creates a time machine but it only works on houseplants\"\n",
    "emoji_version = await narrator.story_to_emoji(original_story, \"sci-fi comedy\")\n",
    "\n",
    "# Decode back to a different story\n",
    "new_story = await narrator.emoji_to_story(\n",
    "    str(emoji_version),\n",
    "    genre=\"philosophical thriller\",\n",
    "    tone=\"mysterious\"\n",
    ")\n",
    "\n",
    "print(f\"Original: {original_story}\\nEmoji: {emoji_version}\\nNew Story: {new_story}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
