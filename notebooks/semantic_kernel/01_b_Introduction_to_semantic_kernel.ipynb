{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QnA Bot Exercise\n",
    "\n",
    "This notebook implements a simple QnA Bot that:\n",
    "1. Stores knowledge in memory\n",
    "2. Answers questions based on that knowledge\n",
    "3. Uses concepts learned in the theory part (01_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "sys.path.append(grandparent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialize Kernel and Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.memory.volatile_memory_store import VolatileMemoryStore\n",
    "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "service_id = \"chat-gpt\"\n",
    "chat_service = AzureChatCompletion(\n",
    "    service_id=service_id,\n",
    ")\n",
    "\n",
    "embedding_service_id = \"embeddings\"\n",
    "kernel.add_service(AzureTextEmbedding(service_id=embedding_service_id))\n",
    "\n",
    "kernel.add_service(chat_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_store = VolatileMemoryStore()\n",
    "memory = SemanticTextMemory(storage=memory_store, embeddings_generator=kernel.get_service(embedding_service_id))\n",
    "kernel.add_plugin(TextMemoryPlugin(memory), \"TextMemoryPlugin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define Prompts (experiment with these!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for answering questions\n",
    "answer_prompt = \"\"\"\n",
    "Context information: {{$context}}\n",
    "\n",
    "User question: {{$question}}\n",
    "\n",
    "Using only the context information above, answer the question.\n",
    "If you cannot answer the question based solely on the context, say \"I don't have enough information to answer that question.\"\n",
    "\n",
    "Answer in this format:\n",
    "ðŸ¤” Question: [restate the question]\n",
    "ðŸ“š Answer: [your answer]\n",
    "\"\"\"\n",
    "\n",
    "answer_function = kernel.add_function(\n",
    "    prompt=answer_prompt,\n",
    "    function_name=\"answer\",\n",
    "    plugin_name=\"QnAPlugin\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store some knowledge\n",
    "await memory.save_information(\n",
    "    collection=\"knowledge\",\n",
    "    id=\"fact1\",\n",
    "    text=\"The semantic kernel was created by Microsoft. It helps developers build AI applications.\",\n",
    ")\n",
    "\n",
    "await memory.save_information(\n",
    "    collection=\"knowledge\",\n",
    "    id=\"fact2\",\n",
    "    text=\"Python is a popular programming language created by Guido van Rossum in 1991.\",\n",
    ")\n",
    "\n",
    "# Ask questions\n",
    "questions = [\n",
    "    \"Who created the semantic kernel?\",\n",
    "    \"When was Python created?\",\n",
    "    \"What is JavaScript?\",  # This should fail as we have no info about JavaScript\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    # Search memory for relevant context\n",
    "    memories = await memory.search(\"knowledge\", question)\n",
    "    context = \"\\n\".join([memory.text for memory in memories])\n",
    "    \n",
    "    # Get answer using the context\n",
    "    answer = await kernel.invoke(\n",
    "        answer_function,\n",
    "        context=context,\n",
    "        question=question\n",
    "    )\n",
    "    print(f\"\\n{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Additional exercises\n",
    "\n",
    "Try these exercises:\n",
    "1. Add more knowledge to the memory\n",
    "2. Modify the answer_prompt to give answers in a different style\n",
    "3. Add a new prompt to summarize all knowledge in memory\n",
    "4. Create a function to check if an answer might be incorrect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
