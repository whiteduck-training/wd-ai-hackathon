{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: A Bad Plan is better Than no Plan\n",
    "## Making AI Think and Remember\n",
    "\n",
    "### 1. Introduction to AI Planning\n",
    "One way to build apps with semantic kernel would be to use the concepts of module 1 and orchestrate those with code... But what if instead of you having to figure out how to chain functions together, the planner can look at all available tools and figure out the best way to solve a problem.\n",
    "\n",
    "### 2. Types of Planners\n",
    "\n",
    "#### 2.1 Sequential Planner\n",
    "The Sequential Planner is the LLM's recipe generator: It analyses tasks and generates a step-by-step plan. Conquer and divide!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.core_plugins import TextPlugin\n",
    "from semantic_kernel.planners import SequentialPlanner\n",
    "from semantic_kernel.functions import kernel_function, KernelFunctionFromPrompt\n",
    "\n",
    "# Set up kernel with OpenAI\n",
    "kernel = Kernel()\n",
    "service_id = \"default\"\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=service_id,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Add the built-in text plugin\n",
    "text_plugin = kernel.add_plugin(TextPlugin(), \"text\")\n",
    "\n",
    "# Create a custom semantic function for creative writing\n",
    "story_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"WriteStory\",\n",
    "    plugin_name=\"WriterPlugin\",\n",
    "    prompt=\"\"\"\n",
    "    Write a short story about: {{$input}}\n",
    "    Make it creative and engaging.\n",
    "    \"\"\",\n",
    "    description=\"Writes a creative short story based on the input.\"\n",
    ")\n",
    "kernel.add_function(plugin_name=\"WriterPlugin\", function=story_function)\n",
    "\n",
    "# Create French translation function\n",
    "translate_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"GriabigerBoarischSprecha\",\n",
    "    plugin_name=\"WriterPlugin\",\n",
    "    prompt=\"\"\"\n",
    "    Translate the following text in very hard to understand bavarian german slang and dialect:\n",
    "    {{$input}}\n",
    "    \"\"\",\n",
    "    description=\"Übasetzt die Eingob in zünftigs Boarisch. Nix für Preißn. Zefix\"\n",
    ")\n",
    "kernel.add_function(plugin_name=\"WriterPlugin\", function=translate_function)\n",
    "\n",
    "# Create our planner\n",
    "planner = SequentialPlanner(kernel, service_id)\n",
    "\n",
    "# Create a plan for a complex task\n",
    "ask = \"\"\"\n",
    "Write a story about a programmer solving a mysterious bug,\n",
    "translate it to crazy german bavarian slang\n",
    "\"\"\"\n",
    "\n",
    "plan = await planner.create_plan(goal=ask)\n",
    "\n",
    "print(\"The plan's steps are:\")\n",
    "for step in plan._steps:\n",
    "    print(f\"- {step.description} using {step.plugin_name}.{step.name}\")\n",
    "\n",
    "result = await plan.invoke(kernel)\n",
    "print(\"\\nFinal Result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Function Calling Stepwise Planner\n",
    "The Stepwise Planner can think and observe as it executes. It's particularly good at tasks that need reasoning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.planners import FunctionCallingStepwisePlanner, FunctionCallingStepwisePlannerOptions\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.core_plugins import MathPlugin, TimePlugin\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "service_id = \"planner\"\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=service_id,\n",
    "    ),\n",
    ")\n",
    "plugin_path = os.path.join(\n",
    "    os.path.dirname(\"../semantic-kernel/prompt_template_samples/WriterPlugin\"),\n",
    "    \"Brainstorm\",\n",
    ")\n",
    "plugin_path = os.path.join(\n",
    "    os.path.dirname(\"../semantic-kernel/prompt_template_samples/EmailPlugin\"),\n",
    "    \"Brainstorm\",\n",
    ")\n",
    "print(plugin_path)\n",
    "# Add necessary plugins\n",
    "kernel.add_plugin(MathPlugin(), \"MathPlugin\")\n",
    "kernel.add_plugin(TimePlugin(), \"TimePlugin\")\n",
    "\n",
    "\n",
    "\n",
    "# Adventure planning questions\n",
    "questions = [\n",
    "    \"Plan a road trip from New York to Boston. Calculate the driving distance and find the best time to start tomorrow morning.\",\n",
    "    \"I want to go hiking for 3 hours. Suggest a starting time and calculate when I’ll be back home.\",\n",
    "    \"What is the sum of the distances 250 miles and 120 miles? Email this result to Sarah.\",\n",
    "]\n",
    "\n",
    "# Planner configuration\n",
    "options = FunctionCallingStepwisePlannerOptions(\n",
    "    max_iterations=10,\n",
    "    max_tokens=4000,\n",
    ")\n",
    "planner = FunctionCallingStepwisePlanner(service_id=service_id, options=options)\n",
    "\n",
    "print(\"🚗 Adventure Planning AI 🚗\\n\")\n",
    "for question in questions:\n",
    "    print(f\"Q: {question}\")\n",
    "    result = await planner.invoke(kernel, question)\n",
    "    print(f\"A: {result.final_answer}\\n\")\n",
    "\n",
    "    # Uncomment this to see step-by-step function calls made by the planner\n",
    "    # print(f\"Chat history:\\n{result.chat_history}\\n\")\n",
    "\n",
    "print(\"✅ Adventure planning completed!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Combining Planners and Memory\n",
    "\n",
    "Let's revisit memory!\n",
    "Finish implementing the next cell to import any kind of data you want into the memory (for example: docs or code from github, parse wikipedia articles etc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.memory import VolatileMemoryStore\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureTextEmbedding\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "\n",
    "from semantic_kernel.memory.volatile_memory_store import VolatileMemoryStore\n",
    "\n",
    "\n",
    "embedding_service_id = \"embeddings\"\n",
    "kernel.add_service(AzureTextEmbedding(service_id=embedding_service_id))\n",
    "\n",
    "# Set up memory system\n",
    "memory_store = VolatileMemoryStore()\n",
    "embeddings = AzureTextEmbedding(\n",
    "    service_id=embedding_service_id\n",
    ")\n",
    "memory = SemanticTextMemory(memory_store, embeddings)\n",
    "\n",
    "# TODO: Add some data to the memory\n",
    "\n",
    "# TODO: Query the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semantic Skills**: AI-powered functions defined by prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from typing import Annotated\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.memory import SemanticTextMemory\n",
    "from semantic_kernel.planners import FunctionCallingStepwisePlanner, FunctionCallingStepwisePlannerOptions\n",
    "from semantic_kernel.functions import kernel_function, KernelFunctionFromPrompt\n",
    "from websearch import WebSearch\n",
    "\n",
    "class WebResearchPlugin:\n",
    "    \"\"\"Plugin for web research capabilities\"\"\"\n",
    "\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"SearchWeb\",\n",
    "        description=\"Searches the web using DuckDuckGo and returns relevant URLs\"\n",
    "    )\n",
    "    def search_web(\n",
    "        self,\n",
    "        query: Annotated[str, \"a query to search the web\"]\n",
    "    ) -> Annotated[str, \"a json result of duckduckgo search\"]:\n",
    "        print(f\"Searching the web for: {query}\")\n",
    "        \n",
    "        url = \"https://stract.com/beta/api/search\"\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        data = {\n",
    "            \"query\": query\n",
    "        }\n",
    "        response = requests.post(url, json=data, headers=headers)\n",
    "        print(response)\n",
    "        return response\n",
    "\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"ExtractContent\",\n",
    "        description=\"Extracts main content from a webpage\"\n",
    "    )\n",
    "    def extract_content(\n",
    "        self,\n",
    "        url: Annotated[str, \"the webpage URL to extract content from\"]\n",
    "    ) -> str:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            for element in soup(['script', 'style', 'nav', 'header', 'footer']):\n",
    "                element.decompose()\n",
    "            \n",
    "            text = soup.get_text(separator=' ', strip=True)\n",
    "            text = text[:2000] + \"...\" if len(text) > 2000 else text\n",
    "            print(f\"Extracted content: {text}\")\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            return f\"Error extracting content: {str(e)}\"\n",
    "\n",
    "class ResearchPlugin:\n",
    "    \"\"\"Plugin for analyzing and summarizing research\"\"\"\n",
    "    \n",
    "    def __init__(self, memory: SemanticTextMemory):\n",
    "        self.memory = memory\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"SaveToMemory\",\n",
    "        description=\"Saves research information to semantic memory\"\n",
    "    )\n",
    "    async def save_to_memory(\n",
    "        self,\n",
    "        content: Annotated[str, \"the content to save to memory\"],\n",
    "        topic: Annotated[str, \"the research topic for categorization\"]\n",
    "    ) -> str:\n",
    "        try:\n",
    "            await self.memory.save_information(\n",
    "                collection=\"research_data\",\n",
    "                text=content,\n",
    "                description=f\"Research on {topic}\",\n",
    "                additional_metadata={\"topic\": topic}\n",
    "            )\n",
    "            return \"Content saved to memory successfully\"\n",
    "        except Exception as e:\n",
    "            return f\"Error saving to memory: {str(e)}\"\n",
    "\n",
    "async def setup_kernel_and_memory():\n",
    "    kernel = Kernel()\n",
    "    \n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    embedding_service_id = \"embeddings\"\n",
    "    kernel.add_service(AzureTextEmbedding(service_id=embedding_service_id))\n",
    "\n",
    "    memory_store = VolatileMemoryStore()\n",
    "    embeddings = AzureTextEmbedding(\n",
    "        service_id=embedding_service_id\n",
    "    )\n",
    "    memory = SemanticTextMemory(memory_store, embeddings)\n",
    "\n",
    "    kernel.add_plugin(WebResearchPlugin(), \"web\")\n",
    "    kernel.add_plugin(ResearchPlugin(memory), \"research\")\n",
    "\n",
    "    analyze_function = KernelFunctionFromPrompt(\n",
    "        function_name=\"AnalyzeContent\",\n",
    "        plugin_name=\"ResearchPlugin\",\n",
    "        prompt=\"\"\"\n",
    "        Content: {{$input}}\n",
    "        \n",
    "        Analyze this content and extract key points. Focus on:\n",
    "        1. Main concepts and ideas\n",
    "        2. Key findings or statements\n",
    "        3. Important relationships\n",
    "        4. Credibility of information\n",
    "        \n",
    "        Format your response as bullet points.\n",
    "        \"\"\",\n",
    "        description=\"Analyzes and extracts key points from content.\"\n",
    "    )\n",
    "\n",
    "    # Fixed the recall syntax in the prompt\n",
    "    summarize_function = KernelFunctionFromPrompt(\n",
    "        function_name=\"CreateSummary\",\n",
    "        plugin_name=\"ResearchPlugin\",\n",
    "        prompt=\"\"\"{{$research_data $topic}}\n",
    "        Research Topic: {{$topic}}\n",
    "        Collected Information:\n",
    "        \n",
    "        Create a comprehensive summary that:\n",
    "        1. Synthesizes the main findings\n",
    "        2. Highlights key agreements and contradictions\n",
    "        3. Identifies gaps in the information\n",
    "        4. Suggests areas for further research\n",
    "        \n",
    "        Keep the summary clear and well-structured.\n",
    "\n",
    "        \n",
    "        \"\"\",\n",
    "        description=\"Creates a summary from collected research.\"\n",
    "    )\n",
    "\n",
    "    kernel.add_function(plugin_name=\"ResearchPlugin\", function=analyze_function)\n",
    "    kernel.add_function(plugin_name=\"ResearchPlugin\", function=summarize_function)\n",
    "\n",
    "    return kernel\n",
    "\n",
    "async def conduct_research(kernel: Kernel, task: str):\n",
    "    planner = FunctionCallingStepwisePlanner(\n",
    "        service_id=\"default\",\n",
    "        options=FunctionCallingStepwisePlannerOptions(\n",
    "            max_iterations=15,\n",
    "            max_tokens=4000,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    try:\n",
    "        print(f\"\\nResearch Task: {task}\\n\")\n",
    "        print(\"Starting research process...\")\n",
    "        \n",
    "        result = await planner.invoke(kernel, task)\n",
    "     \n",
    "      \n",
    "        print(\"\\nResearch Results:\")\n",
    "        print(result.final_answer)\n",
    "        \n",
    "        print(\"\\nThought Process:\")\n",
    "        for thought in result.chat_history:\n",
    "            print(f\"- {thought}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during research: {str(e)}\")\n",
    "\n",
    "# Example research tasks\n",
    "research_tasks = [\n",
    "    \"\"\"\n",
    "    Research the latest developments in quantum computing.\n",
    "    Focus on recent breakthroughs in error correction.\n",
    "    Analyze the information and create a summary.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Find information about artificial intelligence in healthcare.\n",
    "    Focus on recent applications in diagnostic imaging.\n",
    "    Create a summary of the findings.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "print(\"🔍 Web Research Assistant with Semantic Kernel 🔍\\n\")\n",
    "\n",
    "# Setup kernel and memory\n",
    "kernel = await setup_kernel_and_memory()\n",
    "\n",
    "# Process each research task\n",
    "for task in research_tasks:\n",
    "    await conduct_research(kernel, task)\n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Best Practices\n",
    "\n",
    "\n",
    "Always provide clear, specific goals\n",
    "Include error handling\n",
    "Monitor plan execution steps\n",
    "Validate results at each stage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
