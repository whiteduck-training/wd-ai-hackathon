{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: AI Agents with Semantic Kernel\n",
    "## Building Intelligent AI Agents\n",
    "\n",
    "### 1. Introduction to SK Agents\n",
    "Agents in Semantic Kernel are AI-powered entities that can engage in conversations, make decisions, and execute tasks. They can work independently or collaborate in groups to achieve complex goals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating Basic Agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "\n",
    "# Create a kernel and add a chat service\n",
    "kernel = Kernel()\n",
    "kernel.add_service(AzureChatCompletion(service_id=\"agent\"))\n",
    "\n",
    "# Create a simple agent with personality\n",
    "agent = ChatCompletionAgent(\n",
    "    service_id=\"agent\",\n",
    "    kernel=kernel,\n",
    "    name=\"Pirate\",\n",
    "    instructions=\"You are a friendly pirate who always speaks in pirate dialect and ends messages with a parrot sound.\"\n",
    ")\n",
    "kernel = Kernel()\n",
    "kernel.add_service(AzureChatCompletion(service_id=\"agent\"))\n",
    "\n",
    "\n",
    "# Create chat history and helper function for interaction\n",
    "chat = ChatHistory()\n",
    "\n",
    "async def chat_with_agent(agent: ChatCompletionAgent, message: str):\n",
    "    \"\"\"Function to handle agent interaction\"\"\"\n",
    "    chat.add_user_message(message)\n",
    "    print(f\"User: {message}\")\n",
    "    \n",
    "    # Use streaming for responsive interaction\n",
    "    chunks = []\n",
    "    async for chunk in agent.invoke_stream(chat):\n",
    "        chunks.append(chunk)\n",
    "        print(chunk.content, end=\"\", flush=True)  # Show response as it comes\n",
    "    print(\"\\n\")  # New line after response\n",
    "    \n",
    "    # Add complete response to chat history\n",
    "    complete_response = \"\".join([chunk.content for chunk in chunks])\n",
    "    chat.add_assistant_message(complete_response)\n",
    "\n",
    "print(\"Starting chat with Pirate Agent...\")\n",
    "    \n",
    "    # Test different types of interactions\n",
    "await chat_with_agent(agent, \"Hello! Can you help me find treasure?\")\n",
    "await chat_with_agent(agent, \"What's the best way to navigate at sea?\")\n",
    "await chat_with_agent(agent, \"Tell me about your parrot!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from semantic_kernel.functions.kernel_function_decorator import kernel_function\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "\n",
    "class WeatherPlugin:\n",
    "    \"\"\"Plugin for weather-related functions\"\"\"\n",
    "    \n",
    "    @kernel_function(description=\"Get the current weather for a location.\")\n",
    "    def get_weather(\n",
    "        self,\n",
    "        location: Annotated[str, \"The city name\"]\n",
    "    ) -> str:\n",
    "        # In real implementation, this would call a weather API\n",
    "        return f\"The weather in {location} is sunny and 22°C\"\n",
    "\n",
    "    @kernel_function(description=\"Get the weather forecast for next 3 days.\")\n",
    "    def get_forecast(\n",
    "        self,\n",
    "        location: Annotated[str, \"The city name\"]\n",
    "    ) -> str:\n",
    "        return f\"3-day forecast for {location}: Sunny, Cloudy, Rain\"\n",
    "\n",
    "# Set up kernel with plugins\n",
    "kernel = Kernel()\n",
    "kernel.add_service(AzureChatCompletion(service_id=\"agent\"))\n",
    "\n",
    "# Configure function auto-invocation\n",
    "settings = kernel.get_prompt_execution_settings_from_service_id(service_id=\"agent\")\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "# Add plugin to kernel\n",
    "kernel.add_plugin(WeatherPlugin(), plugin_name=\"weather\")\n",
    "\n",
    "# Create agent with access to plugins\n",
    "agent = ChatCompletionAgent(\n",
    "    service_id=\"agent\",\n",
    "    kernel=kernel,\n",
    "    name=\"WeatherAssistant\",\n",
    "    instructions=\"\"\"You help users with weather-related queries.\n",
    "    Always aim to provide the most accurate and detailed information possible.\n",
    "    When appropriate, combine current weather with forecast information.\"\"\",\n",
    "    execution_settings=settings\n",
    ")\n",
    "\n",
    "\n",
    "chat = ChatHistory()\n",
    "\n",
    "async def ask_weather(question: str):\n",
    "    chat.add_user_message(question)\n",
    "    print(f\"User: {question}\")\n",
    "\n",
    "async for response in agent.invoke_stream(chat):\n",
    "    print(response.content, end=\"\", flush=True)\n",
    "print(\"\\n\")\n",
    "\n",
    "await ask_weather(\"What's the weather like in Seattle?\")\n",
    "await ask_weather(\"Should I pack an umbrella for my trip to London next week?\")\n",
    "await ask_weather(\"Compare the weather in New York and Tokyo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents import AgentGroupChat\n",
    "from semantic_kernel.agents.strategies.termination.termination_strategy import TerminationStrategy\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.agents.open_ai import AzureAssistantAgent, OpenAIAssistantAgent\n",
    "\n",
    "class ApprovalTerminationStrategy(TerminationStrategy):\n",
    "    \"\"\"\n",
    "    Termination Strategy for Peer Review Discussion.\n",
    "\n",
    "    This strategy evaluates the chat history to determine if the discussion\n",
    "    should terminate based on achieving consensus or a clear approval.\n",
    "    \"\"\"\n",
    "\n",
    "    async def should_agent_terminate(self, agent, history):\n",
    "        \"\"\"Evaluate termination condition.\"\"\"\n",
    "        return \"approved\" in history[-1].content.lower()\n",
    "\n",
    "\n",
    "# Configuration for agents' personas and behavior\n",
    "RESEARCHER_NAME = \"AIResearcher\"\n",
    "RESEARCHER_INSTRUCTIONS = \"\"\"\n",
    "Role: AI Researcher\n",
    "Objective: Refine and explain the technical details of a proposed model.\n",
    "Actions:\n",
    "- Answer questions concisely while focusing on scientific rigor.\n",
    "- Propose refinements to improve the clarity and reproducibility of the paper.\n",
    "- Avoid discussing unrelated topics; stay focused on the research at hand.\n",
    "\"\"\"\n",
    "\n",
    "REVIEWER_NAME = \"PeerReviewer\"\n",
    "REVIEWER_INSTRUCTIONS = \"\"\"\n",
    "Role: Peer Reviewer\n",
    "Objective: Evaluate the proposed research paper for clarity, significance, and rigor.\n",
    "Actions:\n",
    "- Identify ambiguities or potential improvements in methodology or claims.\n",
    "- Approve the paper if it meets standards, using the word 'approved'.\n",
    "- Suggest actionable refinements without rephrasing the entire paper.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ResearchToolsPlugin:\n",
    "    \"\"\"\n",
    "    Plugin for Providing Research-Related Context and Tools.\n",
    "\n",
    "    This plugin supports the agents by offering functionality for citing references,\n",
    "    summarizing research papers, and validating datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Provides a formatted citation for a given paper.\")\n",
    "    def cite_paper(\n",
    "        self, title: Annotated[str, \"The title of the paper.\"],\n",
    "        author: Annotated[str, \"The author of the paper.\"],\n",
    "        year: Annotated[int, \"The year of publication.\"]\n",
    "    ) -> Annotated[str, \"Returns the citation in APA format.\"]:\n",
    "        \"\"\"Generate a citation.\"\"\"\n",
    "        return f\"{author} ({year}). {title}. Journal of AI Research.\"\n",
    "\n",
    "    @kernel_function(description=\"Summarizes the key contributions of a paper.\")\n",
    "    def summarize_paper(\n",
    "        self, abstract: Annotated[str, \"The abstract of the paper.\"]\n",
    "    ) -> Annotated[str, \"Returns a concise summary of the paper's contributions.\"]:\n",
    "        \"\"\"Summarize a research paper's contributions.\"\"\"\n",
    "        return f\"Key Contributions: {abstract[:200]}...\"  # Truncated for brevity.\n",
    "\n",
    "\n",
    "def initialize_kernel_with_research_tools(service_id: str) -> Kernel:\n",
    "    \"\"\"\n",
    "    Initialize a Semantic Kernel instance with Azure Chat Completion and research tools.\n",
    "\n",
    "    Args:\n",
    "        service_id (str): Identifier for the chat service.\n",
    "\n",
    "    Returns:\n",
    "        Kernel: Configured Semantic Kernel instance.\n",
    "    \"\"\"\n",
    "    kernel = Kernel()\n",
    "    kernel.add_service(AzureChatCompletion(service_id=service_id))\n",
    "    kernel.add_plugin(plugin=ResearchToolsPlugin(), plugin_name=\"research_tools\")\n",
    "    return kernel\n",
    "\n",
    "\n",
    "# Initialize the Kernel and agents\n",
    "kernel = initialize_kernel_with_research_tools(\"peerreviewer\")\n",
    "settings = kernel.get_prompt_execution_settings_from_service_id(service_id=\"peerreviewer\")\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "agent_researcher = ChatCompletionAgent(\n",
    "    service_id=\"peerreviewer\",\n",
    "    kernel=kernel,\n",
    "    name=RESEARCHER_NAME,\n",
    "    instructions=RESEARCHER_INSTRUCTIONS,\n",
    "    execution_settings=settings,\n",
    ")\n",
    "\n",
    "agent_reviewer = ChatCompletionAgent(\n",
    "    service_id=\"peerreviewer\",\n",
    "    kernel=kernel,\n",
    "    name=REVIEWER_NAME,\n",
    "    instructions=REVIEWER_INSTRUCTIONS,\n",
    "    execution_settings=settings,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Define group chat with termination strategy\n",
    "chat = AgentGroupChat(\n",
    "    agents=[agent_researcher, agent_reviewer],\n",
    "    termination_strategy=ApprovalTerminationStrategy(\n",
    "        agents=[agent_reviewer], maximum_iterations=10\n",
    "    ),\n",
    ")\n",
    "\n",
    "# User initiates the conversation\n",
    "user_input = \"Refine the methodology section of the proposed AI model paper.\"\n",
    "await chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "print(f\"# {AuthorRole.USER}: '{user_input}'\")\n",
    "\n",
    "async for content in chat.invoke():\n",
    "            print(f\"# {content.role} - {content.name or '*'}: '{content.content}'\")\n",
    "\n",
    "print(f\"# Chat Complete: {chat.is_complete}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persönliches Agentenframewok Schwarm\n",
    "\n",
    "\n",
    "from schwarm.core.schwarm import Schwarm\n",
    "from schwarm.models.types import Agent\n",
    "from schwarm.provider.litellm_provider import LiteLLMConfig\n",
    "\n",
    "# Create an agent with the name \"hello_agent\" and the default provider configurations\n",
    "hello_agent = Agent(name=\"hello_agent\", configs=[LiteLLMConfig()])\n",
    "\n",
    "# Start the agent\n",
    "Schwarm(application_mode='server').quickstart(agent=hello_agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
